Let's work on building a computer architecture simulation tool named archsim in python. Archsim is a tick based simulator that simulate a computer system's internal behavior and produce insight of the system's performance bottlenecks, performance and other useful information for improve computer architecture. In Archsim, user can define shared resource, such as shared transmission data bus, share memory, time-sharing compute resource, etc. User can specifies the topology that connects the dataflow among these resources.

add arbiter as a building block in the archisim: arbitor allows data from multiple upstream buses to flow into a single downstream bus. The arbiter has several configrable mode: 1) shared: this mode share the downstream bandwidth among all requesters, the transmission will take longer for every winner by interleaving the transfer. 2) scheduled: this mode schedule the winner after all pending downstream transfers complete, using all bandwidth of the downstream bus. The arbiter scheme of choice affects how the downstream bus can complete the data buffer transfer.

Further differentiate the bus for read bus and write bus. Read bus can be specified for read request latency, data response latency and data response bandwidth. Write bus can be specified for write request latency, write bandwidth and write response latency. Put a default latency of 5 cycles respectively.

let's model the response on response bus.



Let's create data buffer which represents is the abstrate data structure that is transferred from one memory to another through the buses. The data buffer can be specified by 1) size in byte that the the total volume to be transfered. 2) content: which can be default to ramdom bytes to start with. later we will allow user to copy special data in it. The memory can alloc and delloc a data buffer. The memory can report all the allocated data buffer total compacity. When a data buffer is scheduled to trasmit to a memory, the memory will allocate it. When a compute consumes a data buffer, the data buffer in the memory will be delloc.

Actually I think it is better to have a global buffer_pool to book keeping all the dynamic data buffers in the system. data buffer can be create with size and content, can be owned by memory instances, can transfer ownership when transmissed from one memory to another. can be deleted when compute on a data buffer complete. Compute can create new data buffer as well. Please update the code.

create a generator resource which can periodically create a data buffer and transmit to a specified memory. Create two instances of the generator to hook to the two buses in the example.

Create a semaphore station whick keep track of an array of semaphores. the total number of semaphores can be speficied, default to be 32. Each semaphore default to a value 0. The supported operation for semaphores are: 1) "signal" a semaphore by increment the semaphore. 2) "wait" a semaphore: a client can wait a semaphore to become larger than 0. When the semaphore value is larger than 0, the client can decrement the semaphore and grant the wait.

we can model the data buffer's states as: 0) allocated 1) transit 2) arrived 3) responded 4) inuse 5) deallocated. At the state transition, it can trigger designated semaphores' operations.

let's build a base class "Channel" from which we derives readbus and writebus. Channel connects an input component to an output component. It has properties: 1) bandwidth 2) latency. Multiple initiators can share a channel through the arbiter. In arbiter, we can include a schedule data structure which keep track of how the future bandwidth of the downstream channel is shared by the initiators. When an initiator makes a new request to use the channel, the arbiter decide how to share the future available bandwidth for this new initiator based on the schedule. In thie process, the future arrival time is recorded in the data buffer in the buffer pool. When the tick reaches the future arrival time, the data buffer's state changes.

From the arbiter, each initiator can have one outstanding data buffer transmission request. After the previous complete, a next data buffer from the same initiator will be arbitrated. Therefore, each arbiter input shall have a fifo to keep track the pending requests. Implemente on the channel a configurable property: 1) interleaving transmit that allows the bandwidth of the channel immediately shared by concurrent requesters. When a new requester is granted to share the bandwidth, all previously granted initiators's data arrival time will be recalculated, because the bandwidth is shared with one more initiator. 2) blocking transmit where a new request will be serviced after all the previously arbiter granted requests finished on the channel. In a way, for each granted requester, the channel bandwidth is allocated exclusively to it and after the transmission completes, the arbiter will pick a next winner to schedule on the channel.

Provide a compact example toggling transfer_mode to compare interleaving vs. blocking arrivals?

provide a function to display the topology, and the the start of each simulation run, display the archsim topology. add trace capability so we can get in each cycle how occupied on each channel, and how may pending requests on each arbiter's inputs. print out a summary of average occupacy at the end of simulation for channels as a table.

let's create a pe (processing element) class from which we can derive various of compute unit and functions. The base PE works as follows: it can have several input data queue and several output data queue. default to 2 input queue and 1 output queue. the pe allow user to customized a "process" function which pops from input queue and do some useful computation and enque the result on the output queue. PE can have a command queue from that it pop a command when the PE is not busy. PE based on the command choose how to handle the input data, thus can perform different operations on the input data. PE has busy and idle state to allow we trace and profile at the end of simulation. Let's define two mode for PE: 1) dummy mode which does not need PE to pop command, when the PE is idle, it greedly pop the head of data inputs and use a random way to combine the input data to generate a output data. 2) pro mode, which can be customized to parse the command and perform more specific tasks. For the PE dummy mode, lets' define a input:output in-out ratio, default to 2:1. this means the total input data buffer volume will generate the output of the size scaled by the in-out ratio. Derive our simple compute unit from this base PE class.

Let's update the databuffer: databuffer needs a field to register the owner memory. Each databuffer is owned by one memory. We need property to differentiate if a databuffer is a source buffer or destination buffer. We create a API for transmiting a source databuffer with the specified destination memory and destination PE's input queue. databuffer transmission happens as follows: first create a destination databuffer which is a copy of the source databuffer but owned by the destination memory and associated with the specified destination PE's input queue. During transmission, both databuffers will be in the transit state. After the trasmission completes, the source buffer will change to deallocated state and the destination buffer will change to arrived state. Upon the arrival of the destination databuffer, it is registerd in the PE's input queue, waiting to be consumed by the PEe.

